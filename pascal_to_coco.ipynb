{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pathlib\n",
    "import json\n",
    "import shutil\n",
    "import os \n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np \n",
    "import cv2 \n",
    "import pycocotools.mask as coco_mask\n",
    "\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation Image copy to SegImg dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc12_root_path = './datasets/VOC2012'\n",
    "image_root_path = './datasets/VOC2012/VOCdevkit/VOC2012/JPEGImages'\n",
    "filelist_path = './datasets/VOC2012/VOCdevkit/VOC2012/ImageSets/Segmentation/trainval.txt'\n",
    "seg_root_path = os.path.join(voc12_root_path, 'SegImages')\n",
    "if not os.path.exists(seg_root_path):\n",
    "    os.makedirs(seg_root_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image copy to Seg dir \n",
    "f = open(filelist_path, 'r')\n",
    "file_list = []\n",
    "line = None\n",
    "while True:\n",
    "    line = f.readline().replace('\\n', '')\n",
    "    if line is None or len(line) == 0 :\n",
    "        break \n",
    "    file_list.append(line + '.jpg')\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(image_root_path, filename)\n",
    "    shutil.copy2(file_path, seg_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert VOC 2 COCO format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_size(ann_file):\n",
    "    # Get the width and height from the annotation file.\n",
    "    ann_file = open(ann_file)\n",
    "    tree = ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "    return width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_annotation_data(ann_file, seg_ann_file, class_agnostic=False):\n",
    "    ann_file = open(ann_file)\n",
    "    tree=ET.parse(ann_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "    seg_img = np.array(Image.open(seg_ann_file))\n",
    "    \n",
    "\n",
    "    annotations = []\n",
    "    for idx,obj in enumerate(root.iter('object')):\n",
    "        idx += 1 \n",
    "        difficult = int(obj.find('difficult').text)\n",
    "\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in CLASSES or difficult==1:\n",
    "            continue\n",
    "\n",
    "        cls_id = 0 if class_agnostic else CLASSES.index(cls)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        bbox = [float(bbox.find(x).text) for x in [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]]\n",
    "        # Original annotations are integers in the range [1, W or H]\n",
    "        # Assuming they mean 1-based pixel indices (inclusive),\n",
    "        # a box with annotation (xmin=1, xmax=W) covers the whole image.\n",
    "        # In coordinate space this is represented by (xmin=0, xmax=W)\n",
    "        bbox[0] -= 1.0\n",
    "        bbox[1] -= 1.0\n",
    "\n",
    "        #Segmentation \n",
    "        #Mask to RLE \n",
    "        bimask = np.where(seg_img == idx, 1,0).astype(np.uint8)\n",
    "        seg = coco_mask.encode(np.asfortranarray(bimask))\n",
    "        seg['counts'] = seg['counts'].decode('utf8')\n",
    "        \n",
    "\n",
    "        annotations.append({\n",
    "            \"iscrowd\": 0, #difficult,\n",
    "            \"bbox\": bbox,\n",
    "            \"segmentation\" : seg,\n",
    "            \"category_id\": cls_id,\n",
    "            \"bbox_mode\": BoxMode.XYXY_ABS}) #\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Year: 2012, ImageSet: trainval, Number of images: 2913\n",
      "Saving the coco-style voc data at ./voc_objects_2012_trainval_CAD_coco_style.json\n"
     ]
    }
   ],
   "source": [
    "#ImageSets 에서 Main이 아니라 Segmentation에 있는 이미지 아이디 가져오기 \n",
    "\n",
    "voc07_dir = './datasets/VOC2007/VOCdevkit/VOC2007'\n",
    "voc12_dir = './datasets/VOC2012/VOCdevkit/VOC2012'\n",
    "voc12_segobj_dir = './datasets/VOC2012/VOCdevkit/VOC2012/SegmentationObject'\n",
    "\n",
    "year2dir = {\"2007\": voc07_dir, \"2012\": voc12_dir}\n",
    "year2segdir = {\"2007\": voc07_dir, \"2012\": voc12_segobj_dir}\n",
    "\n",
    "sets = [('2012', 'trainval')]\n",
    "\n",
    "is_CAD = True\n",
    "\n",
    "CAD_name = \"_CAD\" if is_CAD else \"\"\n",
    "\n",
    "i = 1 \n",
    "for year, image_set in sets:\n",
    "    image_ids = open(f'{year2dir[year]}/ImageSets/Segmentation/{image_set}.txt').read().strip().split()\n",
    "    print(f\"==> Year: {year}, ImageSet: {image_set}, Number of images: {len(image_ids)}\")\n",
    "    data = []\n",
    "    for image_id in image_ids:\n",
    "        full_img_path = pathlib.Path(year2dir[year]) / \"JPEGImages\" / f\"{image_id}.jpg\"\n",
    "        full_ann_path = pathlib.Path(year2dir[year]) / \"Annotations\" / f\"{image_id}.xml\"\n",
    "        width, height = get_img_size(full_ann_path)\n",
    "        assert full_img_path.is_file()\n",
    "        full_seg_ann_path = pathlib.Path(year2segdir[year]) / f\"{image_id}.png\"\n",
    "        data.append({\n",
    "            \"file_name\": str(full_img_path),\n",
    "            \"image_id\": image_id,\n",
    "            \"height\": height, \"width\": width,\n",
    "            \"annotations\": prepare_annotation_data(full_ann_path, full_seg_ann_path, is_CAD),\n",
    "        })\n",
    "        \n",
    "        \n",
    "\n",
    "    # json_data = {\n",
    "    #     \"dataset\": data,\n",
    "    #     \"meta_data\": {\n",
    "    #         \"dirname\": f\"datasets/VOC{year}\",\n",
    "    #         \"evaluator_type\": \"coco\",\n",
    "    #         \"name\": f\"voc_{year}_trainval{CAD_name}_coco_style\",\n",
    "    #         \"split\": image_set,\n",
    "    #         \"year\": int(year),\n",
    "     \n",
    "    json_data = data\n",
    "    \n",
    "    \n",
    "    dst_file = f'./voc_objects_{year}_{image_set}{CAD_name}_coco_style.json'\n",
    "    print(f\"Saving the coco-style voc data at {dst_file}\")\n",
    "    with open(dst_file, 'w') as outfile:\n",
    "        json.dump(json_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('monet_faiss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "594829c9a58650178204aba1b35247961316650bd58720877340f655aa425bf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
